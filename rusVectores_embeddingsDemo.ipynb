{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "RusVectōrēs: семантические модели для русского языка\n",
    "Елизавета Кузьменко, Андрей Кутузов\n",
    "https://github.com/akutuzov/webvectors/blob/master/preprocessing/rusvectores_tutorial.ipynb\n",
    "\n",
    "https://vectors.nlpl.eu/repository/20/180.zip\n",
    "    \"dimensions\": 300,\n",
    "    \"vocabulary size\": 189193,\n",
    "189193 300\n",
    "так_ADV 1.0967804 -2.2944486 1.97916785428456 -1.2069672\n",
    "быть_VERB 0.56827927 -0.3209115 -0.019124394 -1.9356475 \n",
    "мочь_VERB 2.639508 -3.596937 -0.13203041 -0.4291383 0.9506081 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 16:46:11,640 : INFO : loading projection weights from 180_model.bin\n",
      "2025-01-21 16:46:15,265 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (189193, 300) matrix of type float32 from 180_model.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2025-01-21T16:46:15.265992', 'gensim': '4.3.3', 'python': '3.8.20 | packaged by conda-forge | (default, Sep 30 2024, 17:44:03) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "#pip install pymystem3 requests\n",
    "\n",
    "import sys\n",
    "import gensim, logging\n",
    "import numpy as np\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "#import zipfile\n",
    "#model_url = 'http://vectors.nlpl.eu/repository/11/180.zip'\n",
    "#m = wget.download(model_url)\n",
    "#model_file = model_url.split('/')[-1]\n",
    "#model_file = \"180.zip\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "NB\n",
    "\n",
    "\n",
    "Из zip-архива у меня не заработало.\n",
    "Тогда из файла 'http://vectors.nlpl.eu/repository/11/180.zip' \n",
    "вручную выложил в директорию '180_model.bin'\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "extracted_model_file = '180_model.bin'\n",
    "\n",
    "#with zipfile.ZipFile(model_file, 'r') as archive:\n",
    "#Extract the model.bin file to the current directory\n",
    "#archive.extract('model.bin', path='.')\n",
    "\n",
    "# Now load the extracted model file\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(extracted_model_file, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the tokenize_lemmatize_taggize model...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "def tag_mystem(text=\"Текст нужно передать функции в виде строки!\", mapping=None, postags=True):\n",
    "    processed = m.analyze(text)\n",
    "    #https://github.com/nlpub/pymystem3/blob/master/pymystem3/mystem.py\n",
    "    tagged = []\n",
    "    # если частеречные тэги не нужны (например, их нет в модели), выставьте postags=False\n",
    "    # в этом случае на выход будут поданы только леммы\n",
    "   \n",
    "    for w in processed:\n",
    "        try:\n",
    "            lemma = w[\"analysis\"][0][\"lex\"].lower().strip()\n",
    "            pos = w[\"analysis\"][0][\"gr\"].split(\",\")[0]\n",
    "            pos = pos.split(\"=\")[0].strip()\n",
    "            \n",
    "            if mapping:\n",
    "                if pos in mapping:\n",
    "                    pos = mapping[pos]\n",
    "                else:\n",
    "                    pos = \"X\"\n",
    "                    \n",
    "            tagged.append(lemma.lower() + \"_\" + pos)\n",
    "        except KeyError:\n",
    "            continue\n",
    "            \n",
    "    if not postags:\n",
    "        tagged = [t.split(\"_\")[0] for t in tagged]\n",
    "    \n",
    "    return tagged\n",
    "\n",
    "# Таблица преобразования частеречных тэгов Mystem в тэги UPoS:\n",
    "#mapping_url = \"https://raw.githubusercontent.com/akutuzov/universal-pos-tags/4653e8a9154e93fe2f417c7fdb7a357b7d6ce333/ru-rnc.map\"\n",
    "#mystem2upos = {}\n",
    "#r = requests.get(mapping_url, stream=True)\n",
    "\n",
    "#for pair in r.text.split(\"\\n\"):\n",
    "#    pair = pair.split()\n",
    "#    if len(pair) > 1:\n",
    "#        mystem2upos[pair[0]] = pair[1]\n",
    "# Захардкодим таблицу преобразования частеречных тегов Mystem в теги UPoS\n",
    "mystem2upos = {\n",
    "    \"A\": \"ADJ\",\n",
    "    \"ADV\": \"ADV\",\n",
    "    \"ADVPRO\": \"ADV\",\n",
    "    \"ANUM\": \"ADJ\",\n",
    "    \"APRO\": \"DET\",\n",
    "    \"COM\": \"ADJ\",\n",
    "    \"CONJ\": \"SCONJ\",\n",
    "    \"INTJ\": \"INTJ\",\n",
    "    \"NONLEX\": \"X\",\n",
    "    \"NUM\": \"NUM\",\n",
    "    \"PART\": \"PART\",\n",
    "    \"PR\": \"ADP\",\n",
    "    \"S\": \"NOUN\",\n",
    "    \"SPRO\": \"PRON\",\n",
    "    \"UNKN\": \"X\",\n",
    "    \"V\": \"VERB\"\n",
    "}\n",
    "print(\"Loading the tokenize_lemmatize_taggize model...\")\n",
    "m = Mystem()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'analysis': [{'lex': 'стекло', 'wt': 0.9853860572, 'gr': 'S,сред,неод=(вин,ед|им,ед)'}], 'text': 'стекло'}, {'text': '\\n'}]\n",
      "Слово: стекло\n",
      "  Лемма: стекло, Грамм. информация: S,сред,неод=(вин,ед|им,ед)\n",
      "Пробел или пунктуация: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = Mystem()\n",
    "text = \"стекло\"\n",
    "analysis = m.analyze(text)\n",
    "print(analysis)\n",
    "for item in analysis:\n",
    "    if 'analysis' in item:\n",
    "        print(f\"Слово: {item['text']}\")\n",
    "        for variant in item['analysis']:\n",
    "            print(f\"  Лемма: {variant['lex']}, Грамм. информация: {variant['gr']}\")\n",
    "    else:\n",
    "        print(f\"Пробел или пунктуация: {item['text']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#не более 10 слов через пробел. RusVectōrēs сложит вектора положительных слов и вычтет из них \n",
    "#отрицательные. Затем он выдаст слова, наиболее близкие к получившемуся вектору. Если вы оставите\n",
    "# отрицательное поле пустым, RusVectōrēs просто найдет центр лексического кластера, образованного \n",
    "# положительными словами.\n",
    "def tokenize_lemmatize_taggize(input_text):\n",
    "    output = tag_mystem(text=input_text, mapping=mystem2upos)\n",
    "    return \" \".join(output)\n",
    "\n",
    "#result = tokenize_lemmatize_taggize(\"россией священное наши державы\") print(\"test: \" , result)\n",
    "\n",
    "\n",
    "def get_custom_similar_words(model, num_otvetov, positive_str, negative_str):\n",
    "    # Обработка строк и добавление суффикса _NOUN\n",
    "    positive_words = [f\"{word}_NOUN\" for word in positive_str.split()]\n",
    "    negative_words = [f\"{word}_NOUN\" for word in negative_str.split()]\n",
    "\n",
    "    positive_words = [word for word in tokenize_lemmatize_taggize(positive_str).split() if word in model]\n",
    "    negative_words = [word for word in tokenize_lemmatize_taggize(negative_str).split() if word in model]\n",
    "\n",
    "    print(\"++: \", positive_words, \"\\n--: \" , negative_words)\n",
    "    if not positive_words:\n",
    "         return\n",
    "    \n",
    "    ret = np.array([], dtype=str)#    ret = np.unique([], dtype=str)\n",
    "    \n",
    "    # Получаем наиболее похожие слова\n",
    "    for i in model.most_similar(positive=positive_words, negative=negative_words, topn=num_otvetov):\n",
    "            # слово + коэффициент косинусной близости print(i[0], i[1])\n",
    "            processed_string = i[0].split(\"_\")[0]\n",
    "            if processed_string not in ret:\n",
    "                ret = np.append(ret, processed_string)\n",
    "            \n",
    "    #ret = np.unique(ret)\n",
    "    print(' '.join(ret))\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++:  ['чугун_NOUN', 'расплав_NOUN', 'мастер_NOUN'] \n",
      "--:  []\n",
      "огнеупор литье изложница тиголь плавка отливка шихта огнеупорный жаропрочный металл обжиг фурма формовка кристаллизатор шихвать расплава кокс высокопрочный поковка пресс-форма выплавка обжига ковкий мартеновский сталь конвертер формовочный конвертор конвертерный олово плавильный сплаво выплавлять спекание стекломасса карбид битум каолин прокатка легировать литейщик обжигй прессование тугоплавкий электропечь медь низколегированный нержаветь клинкер штамповка цирконий расплавить формовать разливка асбест ниобие монокристалл высокотемпературный электролизер бессемеровский домна легкоплавкий дутье графитовый латунь иттрий ванадий электродуговый титановый вольфрам стеклопластик окалина кокиль заполнитель вагранка марганцевый нержавеющий ковка расплавлять электролитический глинозем сплав шлак сталеплавильный мартен формование болванка электролиз пруток доменный термический ферросплав термообработка литый кокильный футеровка упрочнение чугуна\n"
     ]
    }
   ],
   "source": [
    "get_custom_similar_words(model, 99,\n",
    "                       \"чугун расплав мастер\"\n",
    "                     #   \"трезвость опыт\" # <-- это вычитается\n",
    "                    , \"\"\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слова, которые были в первом массиве, но отсутствуют во втором:\n",
      "козуля\n",
      "чжан-бао\n",
      "гончий\n",
      "лайка\n",
      "тетерево\n",
      "бекас\n",
      "медведица\n",
      "волк\n",
      "кабарга\n",
      "болотец\n",
      "ружье\n",
      "лисица\n",
      "кабан\n",
      "лес\n",
      "валежник\n",
      "ягдташа\n",
      "сеттер\n",
      "легавый\n",
      "борзая\n",
      "стойбище\n",
      "засадка\n",
      "изюбр\n",
      "дрофа\n",
      "заяц\n",
      "стая\n",
      "медведь\n",
      "собака\n",
      "кочка\n",
      "охотник\n",
      "тетеревь\n",
      "егерь\n",
      "тетеревенка\n",
      "козуль\n",
      "нарт\n",
      "зимник\n",
      "косач\n",
      "загонщик\n",
      "утка\n",
      "дичь\n",
      "росомаха\n",
      "одностволка\n",
      "дробовик\n",
      "охотничий\n",
      "зверовый\n",
      "лось\n",
      "дупель\n",
      "вальдшнеп\n",
      "рябчик\n",
      "глухарь\n",
      "куропатка\n",
      "косуля\n",
      "сохатый\n",
      "гончая\n",
      "ружьишко\n",
      "пороша\n",
      "олень\n",
      "выводка\n",
      "борзятник\n",
      "водопой\n",
      "зверь\n"
     ]
    }
   ],
   "source": [
    "# Определяем два массива слов\n",
    "first_array = \"лошадь тропа куст козуль охотник двустволка гончий путик берданка заяц куропатка пес тропка егерь кабан винтовка дробовик опушка коза легавый засадка олень изюбр чаща палка кабарга волк зверовый ружье дичь овраг борзая медведица загонщик лось лес ягдташа гончая рябчик сохатый ездовый кочка сторожка речка рогатина зверь валежник козуля просека тетеревь лесок водопой лайка шалаш охотничий карабин пороша борзятник бекас стая глухарь лощина росомаха зимник собачонка собака изгородь нарты косуля лощинка нарт лисица нарта полверст медведь вальдшнеп косач болотец тетеревенка выводка стойбище дрофа полянка дорожка чжан-бао тетерево сарай сеттер одностволка дупель утка ружьишко косогор\"\n",
    "second_array = \"куст тропка тропа палка дорожка лошадь забор винтовка калитка изгородь жердь пес овраг коновязь плетень сарай просека колышек сторожка поводок косогор полверст дорога веревка сзади карабин берданка загородка опушка лощинка собачонка караульщик бревн мосток хворостина пригорок канава цепь нарта заборчик колышка жердина лощина тропочка гуськом нога путик шалаш мостки конь ворота чаща полянка ограда двустволка сакля загородь будка хворостинка насыпь повозка коза уздечка гать овчарка двор лесин речка крыльцо след улица спешиться лыжа телега марунич лаз караулок спина нарты лесок рогатина ездовый прут канавка развилина стежка сворка шест ствол бугор передка арба обрыв поляна лыжня прогалина\"\n",
    "\n",
    "# Преобразуем строки в списки\n",
    "first_list = first_array.split()\n",
    "second_list = second_array.split()\n",
    "\n",
    "# Находим слова, которые есть в первом массиве, но отсутствуют во втором\n",
    "missing_words = set(first_list) - set(second_list)\n",
    "\n",
    "# Выводим результат\n",
    "print(\"Слова, которые были в первом массиве, но отсутствуют во втором:\")\n",
    "for word in missing_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "su38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
