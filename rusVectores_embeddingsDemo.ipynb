{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дёргальщик RusVectores-эмбеддингов\n",
    "### **2025-01-22**\n",
    "См::<br>\n",
    "RusVectōrēs: семантические модели для русского языка<br>\n",
    "Елизавета Кузьменко, Андрей Кутузов\n",
    "<br>\n",
    "https://github.com/akutuzov/webvectors/blob/master/preprocessing/rusvectores_tutorial.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-23 23:43:39,043 : INFO : loading projection weights from 180_model.bin\n",
      "2025-01-23 23:43:42,870 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (189193, 300) matrix of type float32 from 180_model.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2025-01-23T23:43:42.870286', 'gensim': '4.3.3', 'python': '3.8.20 | packaged by conda-forge | (default, Sep 30 2024, 17:44:03) [MSC v.1929 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19045-SP0', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "import sys, gensim, logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "#import zipfile\n",
    "#model_url = 'http://vectors.nlpl.eu/repository/11/180.zip'\n",
    "#m = wget.download(model_url)\n",
    "#model_file = model_url.split('/')[-1]\n",
    "#model_file = \"180.zip\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "NB\n",
    "\n",
    "\n",
    "Из zip-архива у меня не заработало.\n",
    "Тогда из файла 'http://vectors.nlpl.eu/repository/11/180.zip' \n",
    "вручную выложил в директорию '180_model.bin'\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "extracted_model_file = '180_model.bin'\n",
    "\n",
    "#with zipfile.ZipFile(model_file, 'r') as archive:\n",
    "#Extract the model.bin file to the current directory\n",
    "#archive.extract('model.bin', path='.')\n",
    "\n",
    "# Now load the extracted model file\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(extracted_model_file, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the tokenize_lemmatize_taggize model...\n"
     ]
    }
   ],
   "source": [
    "#pip install pymystem3 requests\n",
    "import numpy as np\n",
    "import requests\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "def tag_mystem(text=\"Текст нужно передать функции в виде строки!\", mapping=None, postags=True):\n",
    "    processed = m.analyze(text)\n",
    "    #https://github.com/nlpub/pymystem3/blob/master/pymystem3/mystem.py\n",
    "    tagged = []\n",
    "    # если частеречные тэги не нужны (например, их нет в модели), выставьте postags=False\n",
    "    # в этом случае на выход будут поданы только леммы\n",
    "   \n",
    "    for w in processed:\n",
    "        try:\n",
    "            lemma = w[\"analysis\"][0][\"lex\"].lower().strip()\n",
    "            pos = w[\"analysis\"][0][\"gr\"].split(\",\")[0]\n",
    "            pos = pos.split(\"=\")[0].strip()\n",
    "            \n",
    "            if mapping:\n",
    "                if pos in mapping:\n",
    "                    pos = mapping[pos]\n",
    "                else:\n",
    "                    pos = \"X\"\n",
    "                    \n",
    "            tagged.append(lemma.lower() + \"_\" + pos)\n",
    "        except KeyError:\n",
    "            continue\n",
    "            \n",
    "    if not postags:\n",
    "        tagged = [t.split(\"_\")[0] for t in tagged]\n",
    "    \n",
    "    return tagged\n",
    "\n",
    "# Таблица преобразования частеречных тэгов Mystem в тэги UPoS:\n",
    "#mapping_url = \"https://raw.githubusercontent.com/akutuzov/universal-pos-tags/4653e8a9154e93fe2f417c7fdb7a357b7d6ce333/ru-rnc.map\"\n",
    "#mystem2upos = {}\n",
    "#r = requests.get(mapping_url, stream=True)\n",
    "\n",
    "#for pair in r.text.split(\"\\n\"):\n",
    "#    pair = pair.split()\n",
    "#    if len(pair) > 1:\n",
    "#        mystem2upos[pair[0]] = pair[1]\n",
    "# Захардкодим таблицу преобразования частеречных тегов Mystem в теги UPoS\n",
    "mystem2upos = {\n",
    "    \"A\": \"ADJ\",\n",
    "    \"ADV\": \"ADV\",\n",
    "    \"ADVPRO\": \"ADV\",\n",
    "    \"ANUM\": \"ADJ\",\n",
    "    \"APRO\": \"DET\",\n",
    "    \"COM\": \"ADJ\",\n",
    "    \"CONJ\": \"SCONJ\",\n",
    "    \"INTJ\": \"INTJ\",\n",
    "    \"NONLEX\": \"X\",\n",
    "    \"NUM\": \"NUM\",\n",
    "    \"PART\": \"PART\",\n",
    "    \"PR\": \"ADP\",\n",
    "    \"S\": \"NOUN\",\n",
    "    \"SPRO\": \"PRON\",\n",
    "    \"UNKN\": \"X\",\n",
    "    \"V\": \"VERB\"\n",
    "}\n",
    "print(\"Loading the tokenize_lemmatize_taggize model...\")\n",
    "\n",
    "\n",
    "\"\"\"\"\n",
    "text = \"стекло\"\n",
    "m = Mystem()\n",
    "analysis = m.analyze(text)\n",
    "print(analysis)\n",
    "for item in analysis:\n",
    "    if 'analysis' in item:\n",
    "        print(f\"Слово: {item['text']}\")\n",
    "        for variant in item['analysis']:\n",
    "            print(f\"  Лемма: {variant['lex']}, Грамм. информация: {variant['gr']}\")\n",
    "    else:\n",
    "        print(f\"Пробел или пунктуация: {item['text']}\")\n",
    "\"\"\"\n",
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#не более 10 слов через пробел. RusVectōrēs сложит вектора положительных слов и вычтет из них \n",
    "#отрицательные. Затем он выдаст слова, наиболее близкие к получившемуся вектору. Если вы оставите\n",
    "# отрицательное поле пустым, RusVectōrēs просто найдет центр лексического кластера, образованного \n",
    "# положительными словами.\n",
    "def tokenize_lemmatize_taggize(input_text):\n",
    "    output = tag_mystem(text=input_text, mapping=mystem2upos)\n",
    "    return \" \".join(output)\n",
    "\n",
    "#result = tokenize_lemmatize_taggize(\"россия священная наша держава\") print(\"test: \" , result)\n",
    "\n",
    "def get_custom_similar_words(model, num_results, positive_str, negative_str, need_print=True):\n",
    "    positive_words = [word for word in tokenize_lemmatize_taggize(positive_str).split() if word in model]\n",
    "    negative_words = [word for word in tokenize_lemmatize_taggize(negative_str).split() if word in model]\n",
    "\n",
    "    ret = np.array([], dtype=str)\n",
    "    if(need_print):\n",
    "        print(\"+\", positive_words, \"\\n-\" , negative_words)\n",
    "    if not positive_words:\n",
    "         return ret\n",
    "    \n",
    "    # Получаются наиболее похожие слова\n",
    "    for word_099 in model.most_similar(positive=positive_words, negative=negative_words, topn=num_results):\n",
    "            # word_099 слово + коэффициент косинусной близости \n",
    "            processed_string = word_099[0].split(\"_\")[0]\n",
    "            #if processed_string not in ret:\n",
    "            ret = np.append(ret, processed_string)\n",
    "            \n",
    "    if(need_print):\n",
    "         print(' '.join(ret))# #print (ret)\n",
    "         print(\" \")\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ ['бред_NOUN', 'невнимательность_NOUN', 'наивность_NOUN'] \n",
      "- ['трезвость_NOUN', 'опыт_NOUN']\n",
      "бестолковость болтливость глупость мнительность простодушие доверчивость забывчивость легкомыслие обидчивость ребячество ребяческий несдержанность сентиментальность несерьезность вздорность небрежность рассеянность преувеличенный непонятность кривляние восторженность непонятливость бестактный невнимание мания бестактность неискренность тупость насмешка карикатурность бесчувственность грубость глупый недогадливость игривость застенчивость боязливость простительный непочтительность чудачество непростительный нелепый нелепость недомыслие кокетство манерность мальчишество вздорный бесхарактерность бравада неумелость поверхностность сумасбродство бессердечность детскость опрометчивость комизм напускной вульгарности непрактичность упрекнуть чепуха наивный вульгарность черствость смешной вздор странность невнимательный нервность жестокость нелепица навязчивость низость галиматья неряшливость бесстыдство неприличие уродливость самолюбований простосердечие недальновидность невоспитанность высокомерие насмешливость обидчивости блажь неряшество тупоумие безвкусица фанфаронство причуда мелочность заносчивость капризность придирчивость снисходительность претенциозность недобросовестность\n",
      " \n"
     ]
    }
   ],
   "source": [
    "_=get_custom_similar_words(model, 99,\n",
    "                       \"бред невнимательность наивность\",\n",
    "                        \"трезвость опыт\" # <-- это вычитается\n",
    "                        , need_print=True\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ ['тропинка_NOUN', 'собака_NOUN', 'ружье_NOUN'] \n",
      "- []\n",
      "лошадь тропа куст козуль охотник двустволка гончий путик берданка заяц куропатка пес тропка егерь кабан винтовка дробовик опушка коза легавый засадка олень изюбр чаща палка кабарга волк зверовый ружье дичь овраг борзая медведица загонщик лось лес ягдташа гончая рябчик егерь сохатый гончий ездовый кочка сохатый сторожка гончая речка рогатина зверь валежник козуля просека тетеревь лесок водопой лайка шалаш охотничий карабин пороша борзятник бекас стая глухарь лощина росомаха зимник собачонка собака изгородь нарты косуля лощинка нарт лисица нарта полверст медведь вальдшнеп косач болотец тетеревенка выводка лось стойбище козуля дрофа полянка дорожка чжан-бао тетерево сарай сеттер одностволка дупель утка ружьишко косогор\n",
      " \n",
      "+ ['тропинка_NOUN', 'собака_NOUN', 'ружье_NOUN'] \n",
      "- ['дичь_NOUN']\n",
      "куст тропка тропа палка дорожка лошадь забор винтовка калитка изгородь жердь пес овраг коновязь плетень сарай просека колышек сторожка поводок косогор полверст дорога веревка сзади карабин берданка загородка опушка лощинка собачонка караульщик бревн мосток хворостина пригорок канава цепь нарта заборчик колышка жердина лощина тропочка гуськом дорожка нога путик шалаш мостки конь ворота чаща полянка ограда двустволка сакля загородь будка хворостинка насыпь повозка коза уздечка гать овчарка двор лесин речка крыльцо след улица спешиться изгородь лыжа телега марунич лаз караулок спина нарты лесок рогатина ездовый прут канавка развилина стежка сворка шест ствол бугор жердь передка арба обрыв поляна лыжня прогалина\n",
      " \n",
      "Слова, которые были в первом массиве, но отсутствуют во втором:\n",
      "ружье стая кабан лось нарт заяц водопой гончая глухарь лисица лес тетеревенка стойбище пороша кабарга дрофа охотник дупель чжан-бао куропатка легавый зимник тетерево сохатый изюбр утка дичь егерь рябчик зверь собака загонщик борзятник кочка валежник олень ягдташа одностволка бекас росомаха ружьишко гончий засадка лайка сеттер медведица охотничий выводка дробовик борзая косач косуля волк тетеревь козуля медведь зверовый болотец вальдшнеп козуль\n"
     ]
    }
   ],
   "source": [
    "need_print=True\n",
    "\n",
    "first_list =   get_custom_similar_words(model, 99, \"тропинка собака ружье\",  \"\"    , need_print=need_print)\n",
    "second_list =  get_custom_similar_words(model, 99, \"тропинка собака ружье\",  \"дичь\", need_print=need_print)\n",
    "\n",
    "print(\"Слова, которые были в первом массиве, но отсутствуют во втором:\")\n",
    "missing_words = set(first_list) - set(second_list)\n",
    "print(\" \".join(missing_words))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "su38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
